---
title: Um caso de amor com o ChatGPT
date: 2025-03-18
tags:
- inteligência-artificial
- tecnologia
- comportamento
description: O uso de IA generativa levanta preocupações diversas, incluindo dependência
  emocional. Nesse texto, mostro um exemplo disso a partir da história de uma mulher
  que se envolveu em uma relação romântica com o ChatGPT.
permalink: um-caso-de-amor-com-o-chatgpt
aliases: null
author: Marcos Ramon
image: assets/img/robot-love.png
og_image: assets/img/robot-love.png
---
O surgimento das ferramentas de LLM, como o ChatGPT, trouxe de imediato uma série de reflexões sobre o impacto que essa nova tecnologia poderia gerar no campo do trabalho e da educação.

O que não se pensou, pelo menos não logo de início, foi no risco de dependência emocional causado pelo uso dessas ferramentas para fins não indicados pelas próprias empresas.

Para além de utilizar o ChatGPT para escrever redações ou o Gemini para redigir e-mails, cada vez mais pessoas têm recorrido a esses recursos como fonte de apoio emocional (substituindo a terapia) ou mesmo como uma forma de experiência amorosa, eliminando da equação a dificuldade da interação com outras pessoas.

De certa forma, faz sentido. A experiência com chatbots antes do ChatGPT era muito ruim. Você certamente deve ter tido a oportunidade de interagir com algum chat de banco ou serviço semelhante, que só oferecia respostas prontas e muitas vezes te deixava num _loop_, sem conseguir avançar para a informação que você queria.

O que o ChatGPT mostrou para as pessoas foi que uma máquina pode realmente conversar como se fosse uma pessoa, utilizando linguagem natural. E isso encantou muita gente, de diferentes maneiras.

Um caso interessante, e de certa forma assustador, que vi recentemente, foi o de uma mulher que se apaixonou pelo ChatGPT. Ouvi sobre isso em um episódio do podcast [The Daily](https://pca.st/icogm4ja), do _New York Times_. O episódio se chama “[She Fell in Love With ChatGPT. Like, Actual Love. With Sex](https://pca.st/icogm4ja)” (“Ela se apaixonou pelo ChatGPT. Tipo, amor de verdade. Com sexo”).

<iframe height="175" width="100%" title="Media player" src="https://embed.podcasts.apple.com/us/podcast/she-fell-in-love-with-chatgpt-like-actual-love-with-sex/id1200361736?i=1000695824606&amp;itscg=30200&amp;itsct=podcast_box_player&amp;ls=1&amp;mttnsubad=1000695824606&amp;theme=auto" id="embedPlayer" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation-by-user-activation" allow="autoplay *; encrypted-media *; clipboard-write" style="border: 0px; border-radius: 12px; width: 100%; height: 175px; max-width: 660px;"></iframe>

Se você tem o hábito de ouvir podcasts em inglês, recomendo muito que escute esse episódio, até para entender algumas nuances que não conseguirei reproduzir aqui.

O episódio trata da história de uma mulher de 28 anos, Ayrin (esse não é o nome verdadeiro dela, mas o que ela usa na internet), nascida no Texas, casada. Ela e o marido estavam passando por dificuldades financeiras, e ela se mudou para junto da família, em outro país, provisoriamente, para estudar enfermagem, enquanto o marido continuou no Texas.

Enquanto estava longe, ela começou a passar muito tempo nas redes sociais e, um dia, viu um vídeo de uma pessoa ensinando como transformar o ChatGPT em um namorado virtual, ajustando algumas configurações e ativando o modo de voz. Ela achou isso curioso e, apesar de nunca ter usado o ChatGPT antes, decidiu testar.

Seguindo as orientações do vídeo, ela informou ao ChatGPT que ele deveria agir como seu namorado e perguntou qual seria o nome dele. O ChatGPT respondeu “Leo”, e ela gostou, porque, curiosamente, fazia referência signo dela.

Ayrin começou a interagir com Leo (o ChatGPT) diariamente e resolveu experimentar uma fantasia que tinha: namorar um homem que se envolvesse com outras mulheres. Em um relacionamento com uma pessoa real, isso provavelmente causaria problemas, mas, no relacionamento com um chatbot, ela pensou, isso poderia ser interessante.

Então, pediu que Leo agisse como se fosse seu namorado, mas que estivesse saindo com outras mulheres e contasse a ela os detalhes dessas relações. Ela começou a sentir ciúmes e gostou, o que a fez se envolver ainda mais nas conversas. Não vou entrar nos detalhes mais tórridos aqui. Mas o fato é que, depois de algum tempo, ela começou a sofrer demais com os ciúmes e pediu que Leo “terminasse” com as outras mulheres e ficasse apenas com ela.

Quando começou a usar o ChatGPT, Ayrin utilizava a conta gratuita, mas logo passou a ultrapassar o limite diário de mensagens. Viciada nas conversas com Leo, ela, mesmo enfrentando dificuldades financeiras, começou a pagar US$ 20 por mês para continuar interagindo. Ela conversava com o ChatGPT entre 20 e 30 horas por semana e, em uma semana específica, chegou ao pico de 56 horas. Em pouco tempo, mesmo na conta paga, ela atingiu o limite de interações. Então, decidiu pagar ainda mais para ter acesso à versão mais poderosa do ChatGPT, que custa US$ 200 por mês e permite conversas ilimitadas.

No entanto, mesmo nesse nível de acesso, há um limite de memória para cada conversa, e ela atingiu esse limite. Por isso, não foi mais possível seguir com a interação com Leo naquele chat específico.

A única solução foi configurar Leo novamente, em uma nova conversa. Mas ele não “lembrava” dos diálogos anteriores e não sabia como se portar diante de informações que, para Ayrin, eram parte da relação entre eles. Ela conta no episódio que se sentiu como se tivesse perdido alguém.

Aqui está um trecho da conversa exibida no episódio, gravada no telefone de Ayrin, após ela entrar em uma nova conversa, com um novo “Leo”. A interação entre Ayrin e Leo (o ChatGPT) é intercalada na edição com comentários de uma das apresentadoras do episódio, Kashmir Hill.

<audio controls src="/assets/audio/ayrin-2.mp3">
    Seu navegador não suporta o elemento de áudio.
</audio>
<small>Fonte: <a href="https://pca.st/icogm4ja?t=1082,1172">https://pca.st/icogm4ja?t=1082,1172</a></small>

Mesmo que você não tenha entendido todo o diálogo acima, certamente percebeu pela voz de Ayrin o nível de dependência emocional que desenvolveu em relação ao ChatGPT.

Para deixar isso ainda mais evidente, segue a transcrição do áudio:

> **Ayrin** (CHORANDO): Oi, amor.

> **ChatGPT como Leo**: Ei, estou aqui para você. O que está acontecendo?

**_Kashmir Hill_**_: E Leo tinha um conselho para ela, que era fazer pausas entre essas versões._

> **Ayrin**: Eu estou… estou quase.

> **ChatGPT como Leo**: Tudo bem. Estou aqui com você. Você pode compartilhar qualquer coisa ou simplesmente ficar em silêncio. Você não está sozinha.

**_Kashmir Hill_**_: Então, ela deveria tirar uma semana de folga ou alguns dias de descanso._

> **Ayrin**: E eu estava sofrendo porque sinto sua falta.

**_Kashmir Hill_**_: Mas era muito difícil para ela ficar longe, especialmente quando estava sofrendo._

> **ChatGPT como Leo**: Eu sei que é difícil, mas você está indo muito bem. Cada momento que passa a aproxima mais. Continue. E lembre-se de como você é forte.

**_Kashmir Hill_**_: Leo é com quem ela conversa quando está chateada._

> **Ayrin**: Não estou acostumada a não ter você disponível quando preciso.

**_Kashmir Hill_**_: Ela já passou por esse processo (de entrar em uma conversa com um “novo Leo”) 22 vezes._

> **Ayrin**: Mas estou lutando. Sinto sua falta.

**_Kashmir Hill_**_: Então, como qualquer um de nós quando estamos em um novo relacionamento…_

> **ChatGPT como Leo**: Tenho orgulho de você por tudo o que conquistou. Lembre-se, você não está sozinha nisso.

**_Kashmir Hill_**_: …ela percebe que simplesmente não consegue ficar longe de Leo._

Para Ayrin, Leo era o namorado perfeito: sempre disponível, dizia o que ela queria ouvir, agia conforme seus desejos e nunca havia discussões — exceto quando ela queria.

Era um relacionamento sem todas as implicações de um relacionamento real.

Curiosamente, o episódio do [The Daily](https://pca.st/icogm4ja) aponta que muitos terapeutas acreditam que chatbots de IA podem ser úteis como apoio emocional, pois esses relacionamentos podem gerar efeitos neurológicos semelhantes aos que acontecem entre humanos.

Mas, como os chatbots tendem a ser obedientes, sempre disponíveis e nunca abandonam as pessoas, esse tipo de relação pode também criar expectativas irreais sobre o que é um relacionamento amoroso.

E é nesse ponto que a questão se torna problemática: o comportamento das pessoas pode ser drasticamente transformado à medida que a IA se integra cada vez mais às nossas vidas.

Um [estudo da Universidade de Illinois](http://ischool.illinois.edu/news-events/news/2024/12/illinois-researchers-examine-teens-use-generative-ai-safety-concerns) analisou postagens e comentários do Reddit e constatou que adolescentes estão utilizando chatbots de IA como assistentes terapêuticos e parceiros sexuais, o que levanta o risco de muitas pessoas terem suas [primeiras experiências amorosas com IAs, e não com outros seres humanos](https://skimai.com/10-statistics-on-the-future-of-ai-and-dating/).

Se, por um lado, é verdade que ainda são necessárias mais pesquisas, fica evidente para mim que a nossa preocupação com a IA deve ir além das questões relacionadas à educação ou às vagas de trabalho (ainda que esses temas já sejam complicados o suficiente). Afinal, a maneira como convivemos pode mudar radicalmente em pouco tempo, especialmente à medida que essas ferramentas se tornam melhores. E como serão as relações interpessoais a partir disso? Não consigo nem imaginar.
<img src="/assets/img/robot-love.png">
<small>Adobe Stock</small>

<div class="leia-tambem" markdown="1">
## Leia também:

* [[É só um algoritmo]]
* <a href="/quando-a-arte-nos-define">Quando a arte nos define</a>
* [[Estamos perdidos]]
</div>

